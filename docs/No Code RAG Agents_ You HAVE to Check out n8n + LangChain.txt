(Transcrito por TurboScribe.ai. Atualize para Ilimitado para remover esta mensagem.)

Construir agentes de AI avançados com RAG definitivamente não é algo que é limitado a aplicações complexas e custom codadas. Hoje, eu vou mostrar como usar o meu tool de automação favorito, N8n, junto com a minha biblioteca favorita para o desenvolvimento de AI, LangChain, para construir um agente de AI RAG completo usando o meu Google Drive como base de conhecimento para que o agente possa responder perguntas usando os documentos que eu upload. E quando eu digo que não há código, eu quero dizer que hoje nós literalmente vamos escrever zero linha de código para construir nosso agente de AI.

E não me enganem, eu adoro codificar meus próprios agentes, mas eu seria estúpido codificá-los sozinho a cada vez quando, muitas vezes, eu posso fazê-los muito simplesmente sem código usando o N8n. O N8n é um tool de automação de trabalho, similar ao Make.com ou Zapier, mas é muito melhor porque você pode hostá-lo sozinho, então você não precisa pagar centenas e centenas de dólares por mês como eu fiz naquela época para o Zapier, e você pode escalar-o infinitamente, então definitivamente mais sobre isso em um vídeo futuro. Mas além disso, o que já faz o N8n incrível, ele se integra diretamente com o LangChain, então é muito, muito fácil construir agentes de AI que são realmente poderosos com chamadas de ferramentas e RAG, assim como o que eu estou a mostrar agora.

Então, sem mais delongas, vamos entrar direto no negócio e ver o quão fácil é construir um agente de RAG sem código. Tudo bem, então eu já construí os workflows do N8n para o meu agente de AI de RAG, porque eu só quero passar por ele com você muito, muito suavemente para te dar um monte de valor muito rapidamente. Você também pode roubar esses workflows de mim se quiser, eu tenho um link para um repositório GitHub na descrição deste vídeo, então você pode descarregar esses workflows como fios JSON, e então você vai para o seu próprio instante N8n, no topo aqui você clica nos três pontos, e então importar do fio, e em segundos você pode trazer esse todo o workflow para o seu próprio instante N8n, então você pode levar isso mais longe e construir algo incrível com RAG.

E então com isso, nós podemos realmente descer no que esse workflow parece. Então, como com o make.com e Zapier, cada workflow em N8n é feita de dois partes coreais. Você tem os seus triggers, que é o que começa esses workflows, e aí você tem as suas ações, os nodes dentro do workflow que realmente fazem coisas, como interagir com a AI, ou seu drive Google, ou seu database de vetores, seja o que for.

Então, o trigger para esse workflow N8n é um input de conversa, então, quando a mensagem de conversa foi recebida, se você clicar nisso, as opções são bem simples, você só dá a autenticação opcionalmente, e também a mensagem inicial que vai estar lá no widget de conversa para o usador quando eles primeiro clicaram nele para interagir com o agente em um chatbot. E então, quando você adiciona isso como um trigger para um N8n workflow, você é imediatamente dado essa opção no meio inferior aqui para abrir uma janela de conversas, e essa é uma das minhas partes favoritas do N8n, faz com que seja tão fácil testar rapidamente seus agentes de AI, porque você tem uma janela de conversas direto no UI para testar coisas, enquanto você está iterando no prompt, ou nas ferramentas, ou no database de vetores, seja o que for. Então, isso faz com que seja tão fácil testar coisas e iterar nas coisas.

E então, nós até vamos estar olhando para isso mais tarde quando eu dar uma demonstração desse agente de AI com o RAG. E então, nós temos o nosso trigger aqui que eu acabei de cobrir, e quando há uma mensagem de conversa que vem através, ela flui imediatamente para o nosso agente de AI RAG, que é um agente de ferramentas que usa a linha LANG abaixo. E então, o jeito que eu sei que isso usa a linha LANG, além de apenas a documentação me dizendo, se eu clicar no ícone de mais aqui para adicionar um novo nodo para o funcionamento, e eu procuro a linha LANG, certamente, o agente de AI, que é o nodo que eu escolhi aqui, é a segunda opção.

E isso só faz tudo para mim. Eu não tenho que encoder nada para ter minhas ferramentas, minha memória e meu modelo de conversa. Se eu quiser me acostumar mais com isso, eu posso usar o nodo de encoder de linha LANG para realmente encoder coisas e eu quero algo mais robusto que talvez o código NEO não possa fazer para mim, porque o código NEO não pode fazer tudo, mas pode fazer a maioria das coisas.

E então, com esse caso de uso, eu só posso usar o agente de AI da linha LANG aqui e ele tem tudo para mim. Ele tem o modelo de conversa, então eu estou usando OpenAI neste caso e eu posso usar qualquer modelo que eu queira. É realmente fácil de setar minhas credências também, eu só preciso de uma chave API.

E então, também, se eu quisesse um modelo de conversa diferente, eu posso clicar neste conector aqui, eu posso usar CLOD se eu quiser escolher ANTHROPIC, eu posso usar GROK ou LLAMA 3.1, eu posso usar OLLAMA, OpenAI, como eu já escolhi. Praticamente tudo que eu realmente me importo está aqui já. E então, mesmo se houver algo mais, como se eu quisesse usar FIREWORKS, por exemplo, talvez eu possa setar código custom aqui, mas para a maioria dos casos, eu estou feliz com tudo aqui.

Então, é simplesmente incrível, sem código necessário para todas essas integrações. E então, também, para a memória de conversa, há muitas opções para isso. Então, eu estou apenas usando a memória de conversa, que é basicamente que vai ser guardado localmente no meu instante N8n, mas há outras opções também.

Então, se eu clicar no conector de memória aqui, podemos usar algo como memória de conversa Postgres. Então, ter uma tabela SQL que maneja todas as conversas, ou usando Redis, por exemplo. Muitas opções aqui também.

E então, para a chamada de ferramentas, a melhor parte do agente AI, onde na verdade temos a integração RAG, há muitas opções para ferramentas também. Então, se eu clicar neste conector, há muitas ferramentas custom que já estão providas para você. Como um calculador ou uma loja de vetores, que é como eu, na verdade, retiro os documentos para responder perguntas com RAG.

E então, a minha parte favorita é que você pode, literalmente, chamar qualquer ferramenta N8n como uma ferramenta. E então, você seta uma ferramenta para fazer algo como interagir com o Google Drive em uma ferramenta multi-passo, que eu vou mostrar um pouco. E então, você apenas diz ao agente AI como usar essa ferramenta, tipo, quais parâmetros para dar.

E então, também, você diz quando usar essa ferramenta, como você faria com qualquer ferramenta que você definiria em código custom. E então, você pode, literalmente, ter todo o poder de qualquer ferramenta N8n que você quiser, mesmo se há um monte de passos lá. Apenas o pacote como uma ferramenta bonita que você pode colocar no seu agente RAG AI.

E então, sim, é realmente coisa legal. E então, há duas ferramentas que eu tenho aqui para este agente. A primeira é aquela ferramenta de loja de vetores construída, onde eu retiro os documentos baseado em uma ferramenta de uso para responder uma pergunta ou algo assim.

E então, eu adiciono isso como uma ferramenta que está conectada aqui. E então, ele me pede para suprimir uma loja de vetores. Então, eu estou apenas usando uma loja de vetores em memória.

Assim como a minha memória de conversa, ela vai ser guardada localmente no meu agente N8n. Então, haverá, tipo, fios que estão lá no servidor que eu estou gerando o meu N8n. Há outras opções também, então, você poderia usar, por exemplo, uma loja de vetores baseado em Supa ou uma loja de vetores de Pine Cone.

Se você quiser minha recomendação, eu realmente recomendo ir com a base de Supa aqui. E a razão para isso é que se eu voltar para a memória de conversa aqui, isso é apenas um bom pequeno golpe de ouro para você aqui, você pode usar uma tabela baseada em Supa postgres para sua memória de conversa. E então, você também pode instalar uma loja de vetores baseado em Supa.

Então, você pode ter tudo administrado para a sua RAG e suas memórias de conversa tudo em um lugar em baseado em Supa. Então, essa é a minha recomendação se você quiser levar algo assim para a produção. Mas apenas para um propósito de demonstração aqui, eu estou gerando tudo localmente para a minha memória e a minha loja de vetores.

E então, para os modelos de embedição, há muitas opções para isso também. Eu estou apenas usando OpenAI para as minhas embedições também. Então, os mesmos credenciais, e então eu estou apenas usando o modelo TextEmbedding3Lar da OpenAI para minhas embedições.

Então, isso é o que realmente leva os diferentes pedaços de documentos que eu coloquei no meu database de vetores e os transforma em vetores para retribuição depois. E então, em cima disso, eu tenho um modelo que está associado com essa ferramenta para retribuir informação. Então, eu estou apenas usando o mesmo GPT-40mini aqui também, porque você vai pegar os documentos do database de vetores, e você precisa de um modelo de linguagem grande para processar isso e escolher a informação certa.

Então, eu estou usando GPT para isso também. Então, isso é tudo para a retribuição do RAG, a parte de retribuição real do RAG. Agora, para colocar documentos na base de conhecimento do database de vetores, eu tenho outro atalho aqui, e esse é um atalho NAN workflow, como eu estava mencionando antes.

Então, a forma como o meu chatbot funciona aqui, e você pode pegar isso de um milhão de maneiras diferentes, é que vai começar com nada no database de vetores, mas eu tenho acesso infinito para o meu Google Drive, então eu posso falar com o meu chatbot AI e dizer que eu tenho esse arquivo no Google Drive, eu quero que você adicione para sua base de conhecimento para referência futura. Então, o que vai fazer para esse atalho aqui é que eu tenho uma pequena descrição que diz usar isso para procurar um arquivo no Google Drive. Então, o usuário pode dizer que eu quero minhas notas de encontro da semana passada para ser adicionado à base de conhecimento, então ele vai procurar para as notas de encontro no Google Drive, baixá-la e adicione-a para a base de conhecimento do database de vetores para uma enquete futura.

Então, essa é a descrição para dizer ao meu agente AI quando usar esse atalho, e então eu tenho parâmetros. Então, em um exemplo de JSON aqui, eu digo ao agente AI quais parâmetros para dar esse workflow para que ele possa executar corretamente. E então, neste caso, eu estou apenas dando um parâmetro aqui, que é uma enquete.

Como você vai procurar o Google Drive para encontrar aquele arquivo para baixar e então adicionar para o database de vetores. Muito, muito simples. Um par de outras opções aqui, como o ID do workflow, então isso diz qual workflow no final para executar para esse atalho, e então também o campo que vai ser saído desse workflow que você quer usar como a resposta.

Isso então diria ao modelo de linguagem o que aconteceu quando ele invocou aquele atalho. Muita, muita coisa simples. Então, o workflow que eu tenho para isso é, na verdade, este aqui.

Então, começa com um webhook, e então isso recebe a enquete, e então passa ela para o Google Drive. Então, deixe-me clicar nisso e mostrar para você. Vai procurar um arquivo ou um folder baseado na enquete aqui.

Então, se você procurar 8-22 Meeting Notes, por exemplo, você encontraria aquele arquivo WordDoc que tem aqueles Meeting Notes no seu Google Drive. E então, no próximo atalho, vai baixar aquele arquivo. Então, depois de baixá-lo, vai extrair o texto desse arquivo.

E então, agora, neste ponto, no workflow, eu tenho todos os textos desse arquivo que eu baixei para o Google Drive, e agora eu posso colocar no meu database de vetores. Então, é adicionado como base de conhecimento, para que o agente AI possa usar isso para responder perguntas depois. E então, para isso, eu estou apenas usando a mesma chave de memória dos documentos do usuário.

Então, a forma como eu retiro meus documentos é usando essa chave de memória, e a forma como eu insiro documentos é também usando essa chave. Caso contrário, essas duas coisas não vão se unir. E então, é um tipo de equipamento similar aqui, onde eu só tenho que escolher as minhas embedidas, nas quais eu vou usar GBT 4.0, ou não GBT 4.0, isso é para o LLM.

Eu vou usar as três embedidas do OpenAI. E então, eu tenho um carregador de dados de default. Então, isso vai basicamente definir como eu pego o meu texto e o coloco como vetores no meu database de vetores.

E então, eu vou dividir em pedaços, basicamente, apenas usando um text splitter de tamanho 1000 pedaços. Então, todas as mesmas coisas que você veria se você for codificar um agente RAG você mesmo, mas você tem todas as customizações de poder ainda dentro de NAN com absolutamente nenhum código. E então, eu não estou realmente perdendo muito aqui, fazendo isso em um workflow com nenhum código, que é a melhor parte disso.

E então, com tudo isso juntos, eu posso agora testar isso um pouco. Então, deixe-me mostrar uma coisa rápida aqui. Eu vou ir para um par de fios que eu tenho aqui para RAG.

Eu tenho duas notas de encontro aqui, uma de 8.22 e uma de 8.23. Isso é apenas dados falsos que eu fiz apenas para ter algo aqui para RAG. Então, o que eu vou fazer é que eu vou dizer ao meu agente AI para adicionar esses para sua base de conhecimento. E então, eu vou perguntar uma pergunta que pode apenas ser respondida quando ele tem isso em sua base de conhecimento.

Então, eu vou voltar para o meu agente RAG aqui. Eu vou salvá-lo e vou para a janela de conversa no meio inferior. E primeiro, eu vou perguntar uma pergunta que ele não deveria saber neste ponto, porque ele não tem essas notas de encontro em sua base de conhecimento.

Eu vou dizer quais são os itens de ação da reunião em 8.22. E vai demorar um pouco para receber uma resposta. Tente encontrá-la no database de vetores. E, com certeza, eu não tenho acesso a aquele folder específico, ou aquele arquivo específico aqui.

E então, eu vou dizer ok, legal. Encontre as notas de reunião 8.22 no drive e adicione-as para a sua base de conhecimento. Eu não tenho que ficar realmente específico em minha pergunta como esta, mas eu estou apenas fazendo isso agora para ter certeza que funciona para uma boa demonstração aqui.

E aí está. E isso foi super rápido também, o que também é uma grande vantagem com o NAN. É rápido.

Então, eu sucessivamente adicionei as notas de reunião para minha base de conhecimento. Então, agora, eu vou perguntar a mesma pergunta aqui. E, desta vez, vai ter uma resposta e vai ser baseada neste arquivo que temos aqui.

Então, os itens de ação da reunião em 8.22 são planejar um budget, fazer um monte de dinheiro, tudo que temos exatamente aqui no nosso arquivo do Google Drive. Então, eu provo que ele não tinha essa informação antes. Eu mostrei em tempo real como eu consegui adicioná-lo e então obter uma resposta deste documento.

E a razão por que você pode querer fazê-lo desta forma, a outra maneira que você poderia fazer é que você poderia apenas enviar cada um dos arquivos no seu Google Drive para a base de conhecimento automaticamente, como todos os dias ou todas as horas, algo assim. E então, isso estaria lá automaticamente na base de conhecimento. Mas quando você faz dessa forma, às vezes, sua base de conhecimento pode ser inundada por um monte de arquivos que você não necessariamente quer ter disponível para a RAG.

E então, desta forma, eu tenho controle sobre exatamente o que eu dou ao meu agente para ter conhecimento de depois, quando eu quero referenciar algo novamente em uma conversa, como talvez lembrar algo como os itens de ação aqui. Então, é por isso que eu tenho setado assim. Mas, sim, há muitas formas que você pode fazer isso.

A melhor parte sobre o NAN é que, qualquer forma que você queira fazê-lo, você pode fazer muito facilmente nesses funcionamentos. Como se fosse, só demorou minutos para criar esse funcionamento para encontrar um arquivo no Google Drive, acessá-lo e colocá-lo na base de conhecimento. Mas você poderia setar algo similar que você faria em uma base de conhecimento para, talvez, retirar arquivos de um folder específico e constantemente hidratar seu database de vectores com esses arquivos.

Há muitas coisas que você pode fazer. Então, é muito, muito, coisa poderosa. A única coisa que eu queria mencionar é que eu tenho um segundo funcionamento envolvido aqui.

E isso é simplesmente um funcionamento para chamar esse Webhook. Então, há um pequeno problema com o NAN que é infeliz, mas eu encontrei um trabalho realmente sólido por aqui. Quando você tem um ferramento que refere um ID de funcionamento, você não pode referenciar o ID de funcionamento do funcionamento que tem o agente.

Então, eu não posso apenas pegar o que eu tenho aqui com o meu ID de funcionamento e derrubá-lo aqui, porque isso dá alguns erros estranhos dizendo que não há credenciais ou algo assim. Então, você tem que referenciar um funcionamento separado. Então, eu só tenho esse funcionamento que depois conecta de volta para esse Webhook dentro do meu funcionamento original.

E a razão que você precisa fazer isso é porque no meu vendedor de vetores de memória, minha chave de memória, diz aqui que está prefixado pelo ID de funcionamento para evitar colisões. Então, se eu estou inserindo em um database de vetores em um funcionamento diferente, vai ter uma chave de memória diferente, porque está prefixado por um ID de funcionamento Então, eu tenho que ter minha retrieval sendo o mesmo funcionamento como eu tenho as inserções, as inserções de dados dentro do database de vetores. Senão, vai ser prefixado por ID de funcionamento diferentes, e então, esse dados não serão disponíveis para o agente.

Então, é como uma coisa muito técnica que eu só tinha que resolver, mas eu resolvi para você agora, e é por isso que haverá dois funcionamentos no repositório GitHub. Mas, sim, é como uma pequena pequena coisa que você tinha que fazer, infelizmente. Mas, no entanto, se você for usar um database de vetores de produção como SupaBase, então você não terá que se preocupar com isso, porque quando você setupa um SuperBase vetor store aqui como a ferramenta para o agente RAG-AI, você consegue definir a chave de memória de uma forma mais dinâmica, onde não vai ser prefixado pelo ID de funcionalidade.

Isso é algo que acabou de ser feito para o SuperBase vetor store, então você não teria esse problema, e você poderia ter esse todo produto para adicionar um arquivo Google Drive para um database de vetores como esse funcionalidade separado, ao invés de ter esse estranho funcionamento onde você precisa invocar esse funcionalidade separado que apenas conecta logo de volta para essa parte desse todo setup de funcionalidade que eu tenho aqui. Então, eu espero que isso faça sentido. Tudo é construído para você neste ponto, então agora você pode apenas levar esses funcionalidades que eu tenho, roubar para você mesmo e expandir sobre isso para fazer a produção de ou para adicionar mais ferramentas, ou para melhorar sobre a RAG, ou as promessas, o que você quiser fazer, isso é seu para brincar com nenhum código em geral, e você pode até embedar isso em um site, então eu vou mostrar isso muito rápido também, apenas para te dar muito aqui, então eu posso pegar o embed, então eu vou para mais informação bem aqui, quando eu abri meu chat janela e eu sei que isso é código, nós não tínhamos que escrever qualquer código, e você não tem que saber código para poder embedar isso, você pode apenas levar isso bem aqui, copia e você pode ir para seu site, eu só vou ir para um editor HTML online aqui, você pode pastá-lo aqui, e então quando eu clico a corrida, eu tenho esse chat no fundo direito, como você vê em vários sites onde eu posso clicar nisso, e aí vamos, nós temos nosso chat bot agora, e eu posso dizer algo como Oi, como você está, e depois, ele me dá uma resposta super super rápido, eu posso dizer quais são os itens de de 822, e então isso vai novamente referenciar o documento com RAG dando as respostas, porque eu já inserei isso no database vetor super legal, então, sim, isso é praticamente tudo para esse trabalho, eu definitivamente vou fazer mais vídeos com RAG com NAN no futuro, porque isso é super poderoso coisa, e uma coisa que eu provavelmente vou fazer é também focar em super base e ter coisas depoidas em produção, então, se você está interessado nisso, me diga, eu realmente apreciaria saber, só para que eu possa saber que isso é algo que você quer ver, e então, eu provavelmente vou fazer um vídeo sobre isso, então, sim, mais RAG para vir, eu espero que você encontrou isso útil, e que você esteja capaz de construir coisas realmente legais com RAG e NAN usando isso como sua fundação, se você encontrou isso ajudoso, eu realmente realmente apreciaria um curtir e se inscrever, e com isso, eu te vejo no próximo vídeo.

(Transcrito por TurboScribe.ai. Atualize para Ilimitado para remover esta mensagem.)